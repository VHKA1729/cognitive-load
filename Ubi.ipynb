{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import statistics as st\n",
    "from scipy.stats import skew \n",
    "from scipy.stats import kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr=pd.read_csv('train/gsr_train.csv',header=None)\n",
    "rr=pd.read_csv('train/rr_train.csv',header=None)\n",
    "hr=pd.read_csv('train/hr_train.csv',header=None)\n",
    "temp=pd.read_csv('train/temp_train.csv',header=None)\n",
    "label=pd.read_csv('train/labels_train.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Spectrum Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/anaconda3/lib/python3.7/site-packages/scipy/signal/spectral.py:1966: UserWarning: nperseg = 256 is greater than input length  = 30, using nperseg = 30\n",
      "  .format(nperseg, input_length))\n"
     ]
    }
   ],
   "source": [
    "gsr_ps=[]\n",
    "for i in range(0,632):    \n",
    "    freqs, psd = signal.welch(gsr.iloc[i])\n",
    "    gsr_ps.append(np.mean(psd))\n",
    "rr_ps=[]\n",
    "for i in range(0,632):    \n",
    "    freqs, psd = signal.welch(rr.iloc[i])\n",
    "    rr_ps.append(np.mean(psd))\n",
    "hr_ps=[]\n",
    "for i in range(0,632):    \n",
    "    freqs, psd = signal.welch(hr.iloc[i])\n",
    "    hr_ps.append(np.mean(psd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_mean=(gsr.mean(axis=1))\n",
    "gsr_mean2_gsr=(gsr.mean(axis=1))**2\n",
    "gsr_var=(gsr.var(axis=1))\n",
    "gsr_med=gsr.median(axis=1)\n",
    "gsr_kurt=gsr.kurt(axis=1)\n",
    "gsr_cs=np.cumsum(gsr,axis=1)[29]\n",
    "#gsr_ps\n",
    "hr_mean=(hr.mean(axis=1))\n",
    "hr_mean2=(hr.mean(axis=1))**2\n",
    "hr_var=(hr.var(axis=1))\n",
    "hr_med=hr.median(axis=1)\n",
    "hr_kurt=hr.kurt(axis=1)\n",
    "hr_cs=np.cumsum(hr,axis=1)[29]\n",
    "#hr_ps\n",
    "\n",
    "rr_mean=(rr.mean(axis=1))\n",
    "rr_mean2=(rr.mean(axis=1))**2\n",
    "rr_var=(rr.var(axis=1))\n",
    "rr_med=rr.median(axis=1)\n",
    "rr_kurt=rr.kurt(axis=1)\n",
    "rr_cs=np.cumsum(rr,axis=1)[29]\n",
    "#rr_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(list(zip(gsr_mean,gsr_var,gsr_med,gsr_kurt,gsr_cs,gsr_ps,hr_mean,hr_var,hr_med,hr_kurt,hr_cs,hr_ps,rr_mean,rr_var,rr_med,rr_kurt,rr_cs,rr_ps,label[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['gsr_mean','gsr_var','gsr_med','gsr_kurt','gsr_cs','gsr_ps','hr_mean','hr_var','hr_med','hr_kurt','hr_cs','hr_ps','rr_mean','rr_var','rr_med','rr_kurt','rr_cs','rr_ps','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gsr_mean</th>\n",
       "      <th>gsr_var</th>\n",
       "      <th>gsr_med</th>\n",
       "      <th>gsr_kurt</th>\n",
       "      <th>gsr_cs</th>\n",
       "      <th>gsr_ps</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>hr_var</th>\n",
       "      <th>hr_med</th>\n",
       "      <th>hr_kurt</th>\n",
       "      <th>hr_cs</th>\n",
       "      <th>hr_ps</th>\n",
       "      <th>rr_mean</th>\n",
       "      <th>rr_var</th>\n",
       "      <th>rr_med</th>\n",
       "      <th>rr_kurt</th>\n",
       "      <th>rr_cs</th>\n",
       "      <th>rr_ps</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.629602</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>1.633575</td>\n",
       "      <td>-1.584146</td>\n",
       "      <td>48.888074</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>62.511111</td>\n",
       "      <td>2.082248</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000413</td>\n",
       "      <td>1875.333333</td>\n",
       "      <td>0.723715</td>\n",
       "      <td>0.942426</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.951275</td>\n",
       "      <td>1.669456</td>\n",
       "      <td>28.272768</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.574807</td>\n",
       "      <td>0.015033</td>\n",
       "      <td>0.655739</td>\n",
       "      <td>-0.966358</td>\n",
       "      <td>17.244212</td>\n",
       "      <td>0.030699</td>\n",
       "      <td>74.933333</td>\n",
       "      <td>5.803831</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>-0.338040</td>\n",
       "      <td>2248.000000</td>\n",
       "      <td>13.899084</td>\n",
       "      <td>0.804159</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.788120</td>\n",
       "      <td>-0.332033</td>\n",
       "      <td>24.124768</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.020229</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>1.039323</td>\n",
       "      <td>0.185807</td>\n",
       "      <td>30.606870</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1.783525</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>4.560340</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>0.823004</td>\n",
       "      <td>0.923990</td>\n",
       "      <td>0.056622</td>\n",
       "      <td>0.956805</td>\n",
       "      <td>3.917334</td>\n",
       "      <td>27.719701</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.507063</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>1.504966</td>\n",
       "      <td>-0.961365</td>\n",
       "      <td>45.211902</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>75.466667</td>\n",
       "      <td>1.383908</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>3.515310</td>\n",
       "      <td>2264.000000</td>\n",
       "      <td>1.438966</td>\n",
       "      <td>0.793835</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.790885</td>\n",
       "      <td>-0.916222</td>\n",
       "      <td>23.815051</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.378422</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.377606</td>\n",
       "      <td>-1.675707</td>\n",
       "      <td>11.352647</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>73.155556</td>\n",
       "      <td>61.285313</td>\n",
       "      <td>76.166667</td>\n",
       "      <td>3.425780</td>\n",
       "      <td>2194.666667</td>\n",
       "      <td>19.293753</td>\n",
       "      <td>0.701381</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.745257</td>\n",
       "      <td>2.406221</td>\n",
       "      <td>21.041421</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>3.120945</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>3.105660</td>\n",
       "      <td>-0.103505</td>\n",
       "      <td>93.628362</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>84.777778</td>\n",
       "      <td>1.527458</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>-0.977876</td>\n",
       "      <td>2543.333333</td>\n",
       "      <td>3.900179</td>\n",
       "      <td>0.698708</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.681655</td>\n",
       "      <td>4.770574</td>\n",
       "      <td>20.961227</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2.678209</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>2.677381</td>\n",
       "      <td>-0.727722</td>\n",
       "      <td>80.346274</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>74.555556</td>\n",
       "      <td>7.220945</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.865552</td>\n",
       "      <td>2236.666667</td>\n",
       "      <td>16.161541</td>\n",
       "      <td>0.790332</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.790885</td>\n",
       "      <td>0.386511</td>\n",
       "      <td>23.709968</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>1.228856</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1.228508</td>\n",
       "      <td>-1.158179</td>\n",
       "      <td>36.865673</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>80.933333</td>\n",
       "      <td>3.305747</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>4.022358</td>\n",
       "      <td>2428.000000</td>\n",
       "      <td>2.051780</td>\n",
       "      <td>0.730601</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.724517</td>\n",
       "      <td>0.257702</td>\n",
       "      <td>21.918032</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>0.659290</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.659197</td>\n",
       "      <td>-1.183209</td>\n",
       "      <td>19.778713</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>72.077778</td>\n",
       "      <td>3.982248</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>-0.156441</td>\n",
       "      <td>2162.333333</td>\n",
       "      <td>5.004645</td>\n",
       "      <td>0.821304</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.824069</td>\n",
       "      <td>0.283480</td>\n",
       "      <td>24.639120</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>0.519258</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.512998</td>\n",
       "      <td>-1.221257</td>\n",
       "      <td>15.577747</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>76.400000</td>\n",
       "      <td>1.489655</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>-0.837560</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>2.299370</td>\n",
       "      <td>0.751249</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.752171</td>\n",
       "      <td>-0.698495</td>\n",
       "      <td>22.537467</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>632 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gsr_mean   gsr_var   gsr_med  gsr_kurt     gsr_cs    gsr_ps    hr_mean  \\\n",
       "0    1.629602  0.000573  1.633575 -1.584146  48.888074  0.000654  62.511111   \n",
       "1    0.574807  0.015033  0.655739 -0.966358  17.244212  0.030699  74.933333   \n",
       "2    1.020229  0.001051  1.039323  0.185807  30.606870  0.000733  62.500000   \n",
       "3    1.507063  0.002732  1.504966 -0.961365  45.211902  0.002291  75.466667   \n",
       "4    0.378422  0.000007  0.377606 -1.675707  11.352647  0.000014  73.155556   \n",
       "..        ...       ...       ...       ...        ...       ...        ...   \n",
       "627  3.120945  0.000644  3.105660 -0.103505  93.628362  0.000703  84.777778   \n",
       "628  2.678209  0.000057  2.677381 -0.727722  80.346274  0.000126  74.555556   \n",
       "629  1.228856  0.000342  1.228508 -1.158179  36.865673  0.000804  80.933333   \n",
       "630  0.659290  0.000012  0.659197 -1.183209  19.778713  0.000005  72.077778   \n",
       "631  0.519258  0.000314  0.512998 -1.221257  15.577747  0.000156  76.400000   \n",
       "\n",
       "        hr_var     hr_med   hr_kurt        hr_cs      hr_ps   rr_mean  \\\n",
       "0     2.082248  62.000000  1.000413  1875.333333   0.723715  0.942426   \n",
       "1     5.803831  74.666667 -0.338040  2248.000000  13.899084  0.804159   \n",
       "2     1.783525  63.000000  4.560340  1875.000000   0.823004  0.923990   \n",
       "3     1.383908  75.666667  3.515310  2264.000000   1.438966  0.793835   \n",
       "4    61.285313  76.166667  3.425780  2194.666667  19.293753  0.701381   \n",
       "..         ...        ...       ...          ...        ...       ...   \n",
       "627   1.527458  84.333333 -0.977876  2543.333333   3.900179  0.698708   \n",
       "628   7.220945  75.000000  0.865552  2236.666667  16.161541  0.790332   \n",
       "629   3.305747  80.333333  4.022358  2428.000000   2.051780  0.730601   \n",
       "630   3.982248  72.000000 -0.156441  2162.333333   5.004645  0.821304   \n",
       "631   1.489655  77.000000 -0.837560  2292.000000   2.299370  0.751249   \n",
       "\n",
       "       rr_var    rr_med   rr_kurt      rr_cs     rr_ps  label  \n",
       "0    0.001626  0.951275  1.669456  28.272768  0.000989      0  \n",
       "1    0.003893  0.788120 -0.332033  24.124768  0.006959      1  \n",
       "2    0.056622  0.956805  3.917334  27.719701  0.008351      1  \n",
       "3    0.000963  0.790885 -0.916222  23.815051  0.001574      0  \n",
       "4    0.017900  0.745257  2.406221  21.041421  0.008772      1  \n",
       "..        ...       ...       ...        ...       ...    ...  \n",
       "627  0.014633  0.681655  4.770574  20.961227  0.031894      0  \n",
       "628  0.004308  0.790885  0.386511  23.709968  0.006209      1  \n",
       "629  0.001604  0.724517  0.257702  21.918032  0.001117      0  \n",
       "630  0.000839  0.824069  0.283480  24.639120  0.001536      0  \n",
       "631  0.000540  0.752171 -0.698495  22.537467  0.000952      0  \n",
       "\n",
       "[632 rows x 19 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.03569933],\n",
       "       [-0.03569933,  1.        ]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(hr_ps,gsr_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df, y_col, x_cols, ratio):\n",
    "    \"\"\" \n",
    "    This method transforms a dataframe into a train and test set, for this you need to specify:\n",
    "    1. the ratio train : test (usually 0.7)\n",
    "    2. the column with the Y_values\n",
    "    \"\"\"\n",
    "    mask = np.random.rand(len(df)) < ratio\n",
    "    df_train = df[mask]\n",
    "    df_test = df[~mask]\n",
    "       \n",
    "    Y_train = df_train[y_col].values\n",
    "    Y_test = df_test[y_col].values\n",
    "    X_train = df_train[x_cols].values\n",
    "    X_test = df_test[x_cols].values\n",
    "    return df_train, df_test, X_train, Y_train, X_test, Y_test\n",
    "\n",
    "y_col = 'label'\n",
    "x_cols = list(df.columns.values)\n",
    "x_cols.remove(y_col)\n",
    "\n",
    "train_test_ratio = 0.7\n",
    "df_train, df_test, X_train, Y_train, X_test, Y_test = get_train_test(df, y_col, x_cols, train_test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(kernel='rbf'),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=1000),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=1000),\n",
    "    \"Neural Net\": MLPClassifier(alpha = 1),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "    \"Gaussian Process\": GaussianProcessClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 5, verbose = True):\n",
    "    \n",
    "    dict_models = {}\n",
    "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
    "        t_start = time.clock()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        t_end = time.clock()\n",
    "        \n",
    "        t_diff = t_end - t_start\n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        test_score = classifier.score(X_test, Y_test)\n",
    "        \n",
    "        dict_models[classifier_name] = {'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff}\n",
    "        if verbose:\n",
    "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
    "    return dict_models\n",
    "\n",
    "\n",
    "\n",
    "def display_dict_models(dict_models, sort_by='test_score'):\n",
    "    cls = [key for key in dict_models.keys()]\n",
    "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
    "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
    "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
    "    \n",
    "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls),4)), columns = ['classifier', 'train_score', 'test_score', 'train_time'])\n",
    "    for ii in range(0,len(cls)):\n",
    "        df_.loc[ii, 'classifier'] = cls[ii]\n",
    "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
    "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
    "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
    "    \n",
    "    display(df_.sort_values(by=sort_by, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Logistic Regression in 0.07 s\n",
      "trained Nearest Neighbors in 0.00 s\n",
      "trained SVM in 0.02 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Gradient Boosting Classifier in 3.40 s\n",
      "trained Decision Tree in 0.01 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Random Forest in 2.87 s\n",
      "trained Neural Net in 0.23 s\n",
      "trained Naive Bayes in 0.00 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained AdaBoost in 0.19 s\n",
      "trained QDA in 0.00 s\n",
      "trained Gaussian Process in 0.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/vineet/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.621891</td>\n",
       "      <td>3.402126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.837587</td>\n",
       "      <td>0.621891</td>\n",
       "      <td>0.194135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.556845</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.572139</td>\n",
       "      <td>2.871751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.562189</td>\n",
       "      <td>0.006521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.554524</td>\n",
       "      <td>0.527363</td>\n",
       "      <td>0.068408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.524362</td>\n",
       "      <td>0.527363</td>\n",
       "      <td>0.002686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.698376</td>\n",
       "      <td>0.517413</td>\n",
       "      <td>0.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gaussian Process</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.151020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.522042</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.015737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.501160</td>\n",
       "      <td>0.482587</td>\n",
       "      <td>0.225533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      classifier  train_score  test_score  train_time\n",
       "3   Gradient Boosting Classifier     1.000000    0.621891    3.402126\n",
       "8                       AdaBoost     0.837587    0.621891    0.194135\n",
       "7                    Naive Bayes     0.556845    0.577114    0.001862\n",
       "5                  Random Forest     1.000000    0.572139    2.871751\n",
       "4                  Decision Tree     1.000000    0.562189    0.006521\n",
       "0            Logistic Regression     0.554524    0.527363    0.068408\n",
       "9                            QDA     0.524362    0.527363    0.002686\n",
       "1              Nearest Neighbors     0.698376    0.517413    0.001462\n",
       "10              Gaussian Process     1.000000    0.497512    0.151020\n",
       "2                            SVM     0.522042    0.492537    0.015737\n",
       "6                     Neural Net     0.501160    0.482587    0.225533"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_models = batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 11)\n",
    "display_dict_models(dict_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For (100, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.62132\n",
      "For (100, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.60662\n",
      "For (100, 0.5, mae) - train, test score: \t 0.73611 \t-\t 0.57353\n",
      "For (100, 0.1, frie) - train, test score: \t 0.98056 \t-\t 0.63971\n",
      "For (100, 0.1, mse) - train, test score: \t 0.98056 \t-\t 0.64338\n",
      "For (100, 0.1, mae) - train, test score: \t 0.73333 \t-\t 0.57721\n",
      "For (100, 0.01, frie) - train, test score: \t 0.78333 \t-\t 0.59559\n",
      "For (100, 0.01, mse) - train, test score: \t 0.78333 \t-\t 0.59926\n",
      "For (100, 0.01, mae) - train, test score: \t 0.71111 \t-\t 0.56985\n",
      "For (100, 0.001, frie) - train, test score: \t 0.66111 \t-\t 0.54779\n",
      "For (100, 0.001, mse) - train, test score: \t 0.66111 \t-\t 0.54779\n",
      "For (100, 0.001, mae) - train, test score: \t 0.56111 \t-\t 0.45956\n",
      "For (500, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.63603\n",
      "For (500, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.63603\n",
      "For (500, 0.5, mae) - train, test score: \t 0.73611 \t-\t 0.57353\n",
      "For (500, 0.1, frie) - train, test score: \t 1.00000 \t-\t 0.63235\n",
      "For (500, 0.1, mse) - train, test score: \t 1.00000 \t-\t 0.63235\n",
      "For (500, 0.1, mae) - train, test score: \t 0.73333 \t-\t 0.57721\n",
      "For (500, 0.01, frie) - train, test score: \t 0.93333 \t-\t 0.64706\n",
      "For (500, 0.01, mse) - train, test score: \t 0.93333 \t-\t 0.64706\n",
      "For (500, 0.01, mae) - train, test score: \t 0.73333 \t-\t 0.57721\n",
      "For (500, 0.001, frie) - train, test score: \t 0.76944 \t-\t 0.58456\n",
      "For (500, 0.001, mse) - train, test score: \t 0.76944 \t-\t 0.58456\n",
      "For (500, 0.001, mae) - train, test score: \t 0.71111 \t-\t 0.56985\n",
      "For (1000, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.63603\n",
      "For (1000, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.63235\n",
      "For (1000, 0.5, mae) - train, test score: \t 0.73611 \t-\t 0.57353\n",
      "For (1000, 0.1, frie) - train, test score: \t 1.00000 \t-\t 0.62868\n",
      "For (1000, 0.1, mse) - train, test score: \t 1.00000 \t-\t 0.62868\n",
      "For (1000, 0.1, mae) - train, test score: \t 0.73333 \t-\t 0.57721\n",
      "For (1000, 0.01, frie) - train, test score: \t 0.99167 \t-\t 0.63603\n",
      "For (1000, 0.01, mse) - train, test score: \t 0.99167 \t-\t 0.63603\n",
      "For (1000, 0.01, mae) - train, test score: \t 0.73333 \t-\t 0.57721\n",
      "For (1000, 0.001, frie) - train, test score: \t 0.78611 \t-\t 0.60294\n",
      "For (1000, 0.001, mse) - train, test score: \t 0.78611 \t-\t 0.60294\n",
      "For (1000, 0.001, mae) - train, test score: \t 0.71111 \t-\t 0.56985\n"
     ]
    }
   ],
   "source": [
    "GDB_params = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.5, 0.1, 0.01, 0.001],\n",
    "    'criterion': ['friedman_mse', 'mse', 'mae']\n",
    "}\n",
    "\n",
    "df_train, df_test, X_train, Y_train, X_test, Y_test = get_train_test(df, y_col, x_cols, 0.6)\n",
    "\n",
    "for n_est in GDB_params['n_estimators']:\n",
    "    for lr in GDB_params['learning_rate']:\n",
    "        for crit in GDB_params['criterion']:\n",
    "            clf = GradientBoostingClassifier(n_estimators=n_est, \n",
    "                                             learning_rate = lr,\n",
    "                                             criterion = crit)\n",
    "            clf.fit(X_train, Y_train)\n",
    "            train_score = clf.score(X_train, Y_train)\n",
    "            test_score = clf.score(X_test, Y_test)\n",
    "            print(\"For ({}, {}, {}) - train, test score: \\t {:.5f} \\t-\\t {:.5f}\".format(n_est, lr, crit[:4], train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
