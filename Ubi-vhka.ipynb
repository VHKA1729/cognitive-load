{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Users/vaibhavanand/Downloads/GitHub_Repos/dashboard-new-env/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/vaibhavanand/Downloads/GitHub_Repos/dashboard-new-env/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8ce4bd50d88b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mXGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Downloads/GitHub_Repos/dashboard-new-env/lib/python3.8/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/GitHub_Repos/dashboard-new-env/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/GitHub_Repos/dashboard-new-env/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mlibname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         raise XGBoostError(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;34m'XGBoost Library ({}) could not be loaded.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;34m'Likely causes:\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Users/vaibhavanand/Downloads/GitHub_Repos/dashboard-new-env/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/vaibhavanand/Downloads/GitHub_Repos/dashboard-new-env/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import statistics as st\n",
    "from scipy.stats import skew \n",
    "from scipy.stats import kurtosis\n",
    "from scipy import signal\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import xgboost as XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "SEED = 1729\n",
    "def determinism(SEED=SEED):\n",
    "    random.seed = SEED\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed = SEED\n",
    "    print('done')\n",
    "    \n",
    "determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr=pd.read_csv('train/gsr_train.csv',header=None)\n",
    "rr=pd.read_csv('train/rr_train.csv',header=None)\n",
    "hr=pd.read_csv('train/hr_train.csv',header=None)\n",
    "temp=pd.read_csv('train/temp_train.csv',header=None)\n",
    "label=pd.read_csv('train/labels_train.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Spectrum Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaibhavanand/Downloads/GitHub_Repos/dashboard-new-env/lib/python3.8/site-packages/scipy/signal/spectral.py:1964: UserWarning: nperseg = 256 is greater than input length  = 30, using nperseg = 30\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    }
   ],
   "source": [
    "gsr_ps=[]\n",
    "for i in range(0,632):    \n",
    "    freqs, psd = signal.welch(gsr.iloc[i])\n",
    "    gsr_ps.append(np.mean(psd))\n",
    "rr_ps=[]\n",
    "for i in range(0,632):    \n",
    "    freqs, psd = signal.welch(rr.iloc[i])\n",
    "    rr_ps.append(np.mean(psd))\n",
    "hr_ps=[]\n",
    "for i in range(0,632):    \n",
    "    freqs, psd = signal.welch(hr.iloc[i])\n",
    "    hr_ps.append(np.mean(psd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsr_mean=(gsr.mean(axis=1))\n",
    "gsr_mean2_gsr=(gsr.mean(axis=1))**2\n",
    "gsr_var=(gsr.var(axis=1))\n",
    "gsr_med=gsr.median(axis=1)\n",
    "gsr_kurt=gsr.kurt(axis=1)\n",
    "gsr_cs=np.cumsum(gsr,axis=1)[29]\n",
    "#gsr_ps\n",
    "hr_mean=(hr.mean(axis=1))\n",
    "hr_mean2=(hr.mean(axis=1))**2\n",
    "hr_var=(hr.var(axis=1))\n",
    "hr_med=hr.median(axis=1)\n",
    "hr_kurt=hr.kurt(axis=1)\n",
    "hr_cs=np.cumsum(hr,axis=1)[29]\n",
    "#hr_ps\n",
    "\n",
    "rr_mean=(rr.mean(axis=1))\n",
    "rr_mean2=(rr.mean(axis=1))**2\n",
    "rr_var=(rr.var(axis=1))\n",
    "rr_med=rr.median(axis=1)\n",
    "rr_kurt=rr.kurt(axis=1)\n",
    "rr_cs=np.cumsum(rr,axis=1)[29]\n",
    "#rr_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(\n",
    "    list(\n",
    "        zip(gsr_mean,gsr_var,gsr_med,gsr_kurt,gsr_cs,gsr_ps,\n",
    "            hr_mean,hr_var,hr_med,hr_kurt,hr_cs,hr_ps,\n",
    "            rr_mean,rr_var,rr_med,rr_kurt,rr_cs,rr_ps,\n",
    "            label[0])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['gsr_mean','gsr_var','gsr_med','gsr_kurt','gsr_cs','gsr_ps',\n",
    "            'hr_mean','hr_var','hr_med','hr_kurt','hr_cs','hr_ps',\n",
    "            'rr_mean','rr_var','rr_med','rr_kurt','rr_cs','rr_ps',\n",
    "            'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gsr_mean</th>\n",
       "      <th>gsr_var</th>\n",
       "      <th>gsr_med</th>\n",
       "      <th>gsr_kurt</th>\n",
       "      <th>gsr_cs</th>\n",
       "      <th>gsr_ps</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>hr_var</th>\n",
       "      <th>hr_med</th>\n",
       "      <th>hr_kurt</th>\n",
       "      <th>hr_cs</th>\n",
       "      <th>hr_ps</th>\n",
       "      <th>rr_mean</th>\n",
       "      <th>rr_var</th>\n",
       "      <th>rr_med</th>\n",
       "      <th>rr_kurt</th>\n",
       "      <th>rr_cs</th>\n",
       "      <th>rr_ps</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.629602</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>1.633575</td>\n",
       "      <td>-1.584146</td>\n",
       "      <td>48.888074</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>62.511111</td>\n",
       "      <td>2.082248</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000413</td>\n",
       "      <td>1875.333333</td>\n",
       "      <td>0.723715</td>\n",
       "      <td>0.942426</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.951275</td>\n",
       "      <td>1.669456</td>\n",
       "      <td>28.272768</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.574807</td>\n",
       "      <td>0.015033</td>\n",
       "      <td>0.655739</td>\n",
       "      <td>-0.966358</td>\n",
       "      <td>17.244212</td>\n",
       "      <td>0.030699</td>\n",
       "      <td>74.933333</td>\n",
       "      <td>5.803831</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>-0.338040</td>\n",
       "      <td>2248.000000</td>\n",
       "      <td>13.899084</td>\n",
       "      <td>0.804159</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.788120</td>\n",
       "      <td>-0.332033</td>\n",
       "      <td>24.124768</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.020229</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>1.039323</td>\n",
       "      <td>0.185807</td>\n",
       "      <td>30.606870</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1.783525</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>4.560340</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>0.823004</td>\n",
       "      <td>0.923990</td>\n",
       "      <td>0.056622</td>\n",
       "      <td>0.956805</td>\n",
       "      <td>3.917334</td>\n",
       "      <td>27.719701</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.507063</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>1.504966</td>\n",
       "      <td>-0.961365</td>\n",
       "      <td>45.211902</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>75.466667</td>\n",
       "      <td>1.383908</td>\n",
       "      <td>75.666667</td>\n",
       "      <td>3.515310</td>\n",
       "      <td>2264.000000</td>\n",
       "      <td>1.438966</td>\n",
       "      <td>0.793835</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.790885</td>\n",
       "      <td>-0.916222</td>\n",
       "      <td>23.815051</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.378422</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.377606</td>\n",
       "      <td>-1.675707</td>\n",
       "      <td>11.352647</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>73.155556</td>\n",
       "      <td>61.285313</td>\n",
       "      <td>76.166667</td>\n",
       "      <td>3.425780</td>\n",
       "      <td>2194.666667</td>\n",
       "      <td>19.293753</td>\n",
       "      <td>0.701381</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.745257</td>\n",
       "      <td>2.406221</td>\n",
       "      <td>21.041421</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>3.120945</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>3.105660</td>\n",
       "      <td>-0.103505</td>\n",
       "      <td>93.628362</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>84.777778</td>\n",
       "      <td>1.527458</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>-0.977876</td>\n",
       "      <td>2543.333333</td>\n",
       "      <td>3.900179</td>\n",
       "      <td>0.698708</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.681655</td>\n",
       "      <td>4.770574</td>\n",
       "      <td>20.961227</td>\n",
       "      <td>0.031894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2.678209</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>2.677381</td>\n",
       "      <td>-0.727722</td>\n",
       "      <td>80.346274</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>74.555556</td>\n",
       "      <td>7.220945</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.865552</td>\n",
       "      <td>2236.666667</td>\n",
       "      <td>16.161541</td>\n",
       "      <td>0.790332</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.790885</td>\n",
       "      <td>0.386511</td>\n",
       "      <td>23.709968</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>1.228856</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1.228508</td>\n",
       "      <td>-1.158179</td>\n",
       "      <td>36.865673</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>80.933333</td>\n",
       "      <td>3.305747</td>\n",
       "      <td>80.333333</td>\n",
       "      <td>4.022358</td>\n",
       "      <td>2428.000000</td>\n",
       "      <td>2.051780</td>\n",
       "      <td>0.730601</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>0.724517</td>\n",
       "      <td>0.257702</td>\n",
       "      <td>21.918032</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>0.659290</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.659197</td>\n",
       "      <td>-1.183209</td>\n",
       "      <td>19.778713</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>72.077778</td>\n",
       "      <td>3.982248</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>-0.156441</td>\n",
       "      <td>2162.333333</td>\n",
       "      <td>5.004645</td>\n",
       "      <td>0.821304</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.824069</td>\n",
       "      <td>0.283480</td>\n",
       "      <td>24.639120</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>0.519258</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.512998</td>\n",
       "      <td>-1.221257</td>\n",
       "      <td>15.577747</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>76.400000</td>\n",
       "      <td>1.489655</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>-0.837560</td>\n",
       "      <td>2292.000000</td>\n",
       "      <td>2.299370</td>\n",
       "      <td>0.751249</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.752171</td>\n",
       "      <td>-0.698495</td>\n",
       "      <td>22.537467</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>632 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gsr_mean   gsr_var   gsr_med  gsr_kurt     gsr_cs    gsr_ps    hr_mean  \\\n",
       "0    1.629602  0.000573  1.633575 -1.584146  48.888074  0.000654  62.511111   \n",
       "1    0.574807  0.015033  0.655739 -0.966358  17.244212  0.030699  74.933333   \n",
       "2    1.020229  0.001051  1.039323  0.185807  30.606870  0.000733  62.500000   \n",
       "3    1.507063  0.002732  1.504966 -0.961365  45.211902  0.002291  75.466667   \n",
       "4    0.378422  0.000007  0.377606 -1.675707  11.352647  0.000014  73.155556   \n",
       "..        ...       ...       ...       ...        ...       ...        ...   \n",
       "627  3.120945  0.000644  3.105660 -0.103505  93.628362  0.000703  84.777778   \n",
       "628  2.678209  0.000057  2.677381 -0.727722  80.346274  0.000126  74.555556   \n",
       "629  1.228856  0.000342  1.228508 -1.158179  36.865673  0.000804  80.933333   \n",
       "630  0.659290  0.000012  0.659197 -1.183209  19.778713  0.000005  72.077778   \n",
       "631  0.519258  0.000314  0.512998 -1.221257  15.577747  0.000156  76.400000   \n",
       "\n",
       "        hr_var     hr_med   hr_kurt        hr_cs      hr_ps   rr_mean  \\\n",
       "0     2.082248  62.000000  1.000413  1875.333333   0.723715  0.942426   \n",
       "1     5.803831  74.666667 -0.338040  2248.000000  13.899084  0.804159   \n",
       "2     1.783525  63.000000  4.560340  1875.000000   0.823004  0.923990   \n",
       "3     1.383908  75.666667  3.515310  2264.000000   1.438966  0.793835   \n",
       "4    61.285313  76.166667  3.425780  2194.666667  19.293753  0.701381   \n",
       "..         ...        ...       ...          ...        ...       ...   \n",
       "627   1.527458  84.333333 -0.977876  2543.333333   3.900179  0.698708   \n",
       "628   7.220945  75.000000  0.865552  2236.666667  16.161541  0.790332   \n",
       "629   3.305747  80.333333  4.022358  2428.000000   2.051780  0.730601   \n",
       "630   3.982248  72.000000 -0.156441  2162.333333   5.004645  0.821304   \n",
       "631   1.489655  77.000000 -0.837560  2292.000000   2.299370  0.751249   \n",
       "\n",
       "       rr_var    rr_med   rr_kurt      rr_cs     rr_ps  label  \n",
       "0    0.001626  0.951275  1.669456  28.272768  0.000989      0  \n",
       "1    0.003893  0.788120 -0.332033  24.124768  0.006959      1  \n",
       "2    0.056622  0.956805  3.917334  27.719701  0.008351      1  \n",
       "3    0.000963  0.790885 -0.916222  23.815051  0.001574      0  \n",
       "4    0.017900  0.745257  2.406221  21.041421  0.008772      1  \n",
       "..        ...       ...       ...        ...       ...    ...  \n",
       "627  0.014633  0.681655  4.770574  20.961227  0.031894      0  \n",
       "628  0.004308  0.790885  0.386511  23.709968  0.006209      1  \n",
       "629  0.001604  0.724517  0.257702  21.918032  0.001117      0  \n",
       "630  0.000839  0.824069  0.283480  24.639120  0.001536      0  \n",
       "631  0.000540  0.752171 -0.698495  22.537467  0.000952      0  \n",
       "\n",
       "[632 rows x 19 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.03569933],\n",
       "       [-0.03569933,  1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(hr_ps,gsr_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df, y_col, x_cols, ratio):\n",
    "    \"\"\" \n",
    "    This method transforms a dataframe into a train and test set, for this you need to specify:\n",
    "    1. the ratio train : test (usually 0.7)\n",
    "    2. the column with the Y_values\n",
    "    \"\"\"\n",
    "    mask = np.random.rand(len(df)) < ratio\n",
    "    df_train = df[mask]\n",
    "    df_test = df[~mask]\n",
    "       \n",
    "    Y_train = df_train[y_col].values\n",
    "    Y_test = df_test[y_col].values\n",
    "    X_train = df_train[x_cols].values\n",
    "    X_test = df_test[x_cols].values\n",
    "    return df_train, df_test, X_train, Y_train, X_test, Y_test\n",
    "\n",
    "y_col = 'label'\n",
    "x_cols = list(df.columns.values)\n",
    "x_cols.remove(y_col)\n",
    "\n",
    "train_test_ratio = 0.7\n",
    "df_train, df_test, X_train, Y_train, X_test, Y_test = get_train_test(df, y_col, x_cols, train_test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(kernel='rbf'),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=1000),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=1000),\n",
    "    \"Neural Net\": MLPClassifier(alpha = 1),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
    "    \"Gaussian Process\": GaussianProcessClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 5, verbose = True):\n",
    "    \n",
    "    dict_models = {}\n",
    "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
    "        t_start = time.clock()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        t_end = time.clock()\n",
    "        \n",
    "        t_diff = t_end - t_start\n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        test_score = classifier.score(X_test, Y_test)\n",
    "        \n",
    "        dict_models[classifier_name] = {'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff}\n",
    "        if verbose:\n",
    "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
    "    return dict_models\n",
    "\n",
    "\n",
    "\n",
    "def display_dict_models(dict_models, sort_by='test_score'):\n",
    "    cls = [key for key in dict_models.keys()]\n",
    "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
    "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
    "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
    "    \n",
    "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls),4)), columns = ['classifier', 'train_score', 'test_score', 'train_time'])\n",
    "    for ii in range(0,len(cls)):\n",
    "        df_.loc[ii, 'classifier'] = cls[ii]\n",
    "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
    "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
    "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
    "    \n",
    "    display(df_.sort_values(by=sort_by, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'time' has no attribute 'clock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-ef35ec3609d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_classifiers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay_dict_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-192f13d51823>\u001b[0m in \u001b[0;36mbatch_classify\u001b[0;34m(X_train, Y_train, X_test, Y_test, no_classifiers, verbose)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdict_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclassifier_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_classifiers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mno_classifiers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mt_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'time' has no attribute 'clock'"
     ]
    }
   ],
   "source": [
    "dict_models = batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 11)\n",
    "display_dict_models(dict_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For (100, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.57028\n",
      "For (100, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.57028\n",
      "For (100, 0.5, mae) - train, test score: \t 0.75196 \t-\t 0.52610\n",
      "For (100, 0.1, frie) - train, test score: \t 0.98695 \t-\t 0.55020\n",
      "For (100, 0.1, mse) - train, test score: \t 0.98695 \t-\t 0.54618\n",
      "For (100, 0.1, mae) - train, test score: \t 0.74935 \t-\t 0.53012\n",
      "For (100, 0.01, frie) - train, test score: \t 0.77023 \t-\t 0.55020\n",
      "For (100, 0.01, mse) - train, test score: \t 0.77023 \t-\t 0.55020\n",
      "For (100, 0.01, mae) - train, test score: \t 0.72585 \t-\t 0.52209\n",
      "For (100, 0.001, frie) - train, test score: \t 0.72324 \t-\t 0.55020\n",
      "For (100, 0.001, mse) - train, test score: \t 0.72324 \t-\t 0.55020\n",
      "For (100, 0.001, mae) - train, test score: \t 0.73629 \t-\t 0.54217\n",
      "For (500, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.57028\n",
      "For (500, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.56627\n",
      "For (500, 0.5, mae) - train, test score: \t 0.74935 \t-\t 0.52610\n",
      "For (500, 0.1, frie) - train, test score: \t 1.00000 \t-\t 0.56627\n",
      "For (500, 0.1, mse) - train, test score: \t 1.00000 \t-\t 0.56627\n",
      "For (500, 0.1, mae) - train, test score: \t 0.74935 \t-\t 0.52610\n",
      "For (500, 0.01, frie) - train, test score: \t 0.91645 \t-\t 0.55823\n",
      "For (500, 0.01, mse) - train, test score: \t 0.91645 \t-\t 0.55422\n",
      "For (500, 0.01, mae) - train, test score: \t 0.74413 \t-\t 0.53012\n",
      "For (500, 0.001, frie) - train, test score: \t 0.75457 \t-\t 0.55020\n",
      "For (500, 0.001, mse) - train, test score: \t 0.75457 \t-\t 0.55020\n",
      "For (500, 0.001, mae) - train, test score: \t 0.72585 \t-\t 0.52209\n",
      "For (1000, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.56627\n",
      "For (1000, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.56627\n",
      "For (1000, 0.5, mae) - train, test score: \t 0.74935 \t-\t 0.53012\n",
      "For (1000, 0.1, frie) - train, test score: \t 1.00000 \t-\t 0.57028\n",
      "For (1000, 0.1, mse) - train, test score: \t 1.00000 \t-\t 0.57430\n",
      "For (1000, 0.1, mae) - train, test score: \t 0.74935 \t-\t 0.52610\n",
      "For (1000, 0.01, frie) - train, test score: \t 0.98433 \t-\t 0.55422\n",
      "For (1000, 0.01, mse) - train, test score: \t 0.98433 \t-\t 0.55422\n",
      "For (1000, 0.01, mae) - train, test score: \t 0.74674 \t-\t 0.53012\n",
      "For (1000, 0.001, frie) - train, test score: \t 0.76501 \t-\t 0.55020\n",
      "For (1000, 0.001, mse) - train, test score: \t 0.76501 \t-\t 0.55020\n",
      "For (1000, 0.001, mae) - train, test score: \t 0.72585 \t-\t 0.52209\n"
     ]
    }
   ],
   "source": [
    "GDB_params = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'learning_rate': [0.5, 0.1, 0.01, 0.001],\n",
    "    'criterion': ['friedman_mse', 'mse', 'mae']\n",
    "}\n",
    "\n",
    "df_train, df_test, X_train, Y_train, X_test, Y_test = get_train_test(df, y_col, x_cols, 0.6)\n",
    "\n",
    "for n_est in GDB_params['n_estimators']:\n",
    "    for lr in GDB_params['learning_rate']:\n",
    "        for crit in GDB_params['criterion']:\n",
    "            clf = GradientBoostingClassifier(n_estimators=n_est, \n",
    "                                             learning_rate = lr,\n",
    "                                             criterion = crit)\n",
    "            clf.fit(X_train, Y_train)\n",
    "            train_score = clf.score(X_train, Y_train)\n",
    "            test_score = clf.score(X_test, Y_test)\n",
    "            print(\"For ({}, {}, {}) - train, test score: \\t {:.5f} \\t-\\t {:.5f}\".format(n_est, lr, crit[:4], train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
