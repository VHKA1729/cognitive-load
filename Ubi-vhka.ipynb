{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Ubi-vhka.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISgXM-YznOLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import statistics as st\n",
        "from scipy.stats import skew \n",
        "from scipy.stats import kurtosis\n",
        "from scipy import signal\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "\n",
        "import xgboost as xgb"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Onj_7T2nOLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7dfe8a3-9d71-47ac-abb3-af0ebd107947"
      },
      "source": [
        "SEED = 1729\n",
        "def determinism(SEED=SEED):\n",
        "    random.seed = SEED\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed = SEED\n",
        "    print('done')\n",
        "    \n",
        "determinism()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESAqUZwZnOLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gsr=pd.read_csv('/content/gsr_train.csv',header=None)\n",
        "rr=pd.read_csv('/content/rr_train.csv',header=None)\n",
        "hr=pd.read_csv('/content/hr_train.csv',header=None)\n",
        "temp=pd.read_csv('/content/temp_train.csv',header=None)\n",
        "label=pd.read_csv('/content/labels_train.csv',header=None)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6Vj9HZZnOL5",
        "colab_type": "text"
      },
      "source": [
        "Power Spectrum Calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxaoNEsfnOL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d8bb0b12-f630-4d7d-da12-0f47bfdb5904"
      },
      "source": [
        "gsr_ps=[]\n",
        "for i in range(0,632):    \n",
        "    freqs, psd = signal.welch(gsr.iloc[i])\n",
        "    gsr_ps.append(np.mean(psd))\n",
        "rr_ps=[]\n",
        "for i in range(0,632):    \n",
        "    freqs, psd = signal.welch(rr.iloc[i])\n",
        "    rr_ps.append(np.mean(psd))\n",
        "hr_ps=[]\n",
        "for i in range(0,632):    \n",
        "    freqs, psd = signal.welch(hr.iloc[i])\n",
        "    hr_ps.append(np.mean(psd))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/signal/spectral.py:1966: UserWarning: nperseg = 256 is greater than input length  = 30, using nperseg = 30\n",
            "  .format(nperseg, input_length))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ipy4nJenOL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gsr_mean=(gsr.mean(axis=1))\n",
        "gsr_mean2_gsr=(gsr.mean(axis=1))**2\n",
        "#gsr_var=(gsr.var(axis=1))\n",
        "gsr_var=(gsr.sd(axis=1))\n",
        "gsr_med=gsr.median(axis=1)\n",
        "gsr_kurt=gsr.kurt(axis=1)\n",
        "gsr_cs=np.cumsum(gsr,axis=1)[29]\n",
        "#gsr_ps\n",
        "hr_mean=(hr.mean(axis=1))\n",
        "hr_mean2=(hr.mean(axis=1))**2\n",
        "#hr_var=(hr.var(axis=1))\n",
        "hr_var=(hr.sd(axis=1))\n",
        "hr_med=hr.median(axis=1)\n",
        "hr_kurt=hr.kurt(axis=1)\n",
        "hr_cs=np.cumsum(hr,axis=1)[29]\n",
        "#hr_ps\n",
        "\n",
        "rr_mean=(rr.mean(axis=1))\n",
        "rr_mean2=(rr.mean(axis=1))**2\n",
        "#rr_var=(rr.var(axis=1))\n",
        "rr_var=(rr.sd(axis=1))\n",
        "rr_med=rr.median(axis=1)\n",
        "rr_kurt=rr.kurt(axis=1)\n",
        "rr_cs=np.cumsum(rr,axis=1)[29]\n",
        "#rr_ps\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfNAIReynOMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame(\n",
        "    list(\n",
        "        zip(gsr_mean,gsr_var,gsr_med,gsr_kurt,gsr_cs,gsr_ps,\n",
        "            hr_mean,hr_var,hr_med,hr_kurt,hr_cs,hr_ps,\n",
        "            rr_mean,rr_var,rr_med,rr_kurt,rr_cs,rr_ps,\n",
        "            label[0])))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U_R1xebnOMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns=['gsr_mean','gsr_var','gsr_med','gsr_kurt','gsr_cs','gsr_ps',\n",
        "            'hr_mean','hr_var','hr_med','hr_kurt','hr_cs','hr_ps',\n",
        "            'rr_mean','rr_var','rr_med','rr_kurt','rr_cs','rr_ps',\n",
        "            'label']\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEOGdnCDnOMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "7b9d61a5-94b4-4889-c534-1127b52132d1"
      },
      "source": [
        "df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gsr_mean</th>\n",
              "      <th>gsr_var</th>\n",
              "      <th>gsr_med</th>\n",
              "      <th>gsr_kurt</th>\n",
              "      <th>gsr_cs</th>\n",
              "      <th>gsr_ps</th>\n",
              "      <th>hr_mean</th>\n",
              "      <th>hr_var</th>\n",
              "      <th>hr_med</th>\n",
              "      <th>hr_kurt</th>\n",
              "      <th>hr_cs</th>\n",
              "      <th>hr_ps</th>\n",
              "      <th>rr_mean</th>\n",
              "      <th>rr_var</th>\n",
              "      <th>rr_med</th>\n",
              "      <th>rr_kurt</th>\n",
              "      <th>rr_cs</th>\n",
              "      <th>rr_ps</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.629602</td>\n",
              "      <td>0.000573</td>\n",
              "      <td>1.633575</td>\n",
              "      <td>-1.584146</td>\n",
              "      <td>48.888074</td>\n",
              "      <td>0.000654</td>\n",
              "      <td>62.511111</td>\n",
              "      <td>2.082248</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>1.000413</td>\n",
              "      <td>1875.333333</td>\n",
              "      <td>0.723715</td>\n",
              "      <td>0.942426</td>\n",
              "      <td>0.001626</td>\n",
              "      <td>0.951275</td>\n",
              "      <td>1.669456</td>\n",
              "      <td>28.272768</td>\n",
              "      <td>0.000989</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.574807</td>\n",
              "      <td>0.015033</td>\n",
              "      <td>0.655739</td>\n",
              "      <td>-0.966358</td>\n",
              "      <td>17.244212</td>\n",
              "      <td>0.030699</td>\n",
              "      <td>74.933333</td>\n",
              "      <td>5.803831</td>\n",
              "      <td>74.666667</td>\n",
              "      <td>-0.338040</td>\n",
              "      <td>2248.000000</td>\n",
              "      <td>13.899084</td>\n",
              "      <td>0.804159</td>\n",
              "      <td>0.003893</td>\n",
              "      <td>0.788120</td>\n",
              "      <td>-0.332033</td>\n",
              "      <td>24.124768</td>\n",
              "      <td>0.006959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.020229</td>\n",
              "      <td>0.001051</td>\n",
              "      <td>1.039323</td>\n",
              "      <td>0.185807</td>\n",
              "      <td>30.606870</td>\n",
              "      <td>0.000733</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1.783525</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>4.560340</td>\n",
              "      <td>1875.000000</td>\n",
              "      <td>0.823004</td>\n",
              "      <td>0.923990</td>\n",
              "      <td>0.056622</td>\n",
              "      <td>0.956805</td>\n",
              "      <td>3.917334</td>\n",
              "      <td>27.719701</td>\n",
              "      <td>0.008351</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.507063</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>1.504966</td>\n",
              "      <td>-0.961365</td>\n",
              "      <td>45.211902</td>\n",
              "      <td>0.002291</td>\n",
              "      <td>75.466667</td>\n",
              "      <td>1.383908</td>\n",
              "      <td>75.666667</td>\n",
              "      <td>3.515310</td>\n",
              "      <td>2264.000000</td>\n",
              "      <td>1.438966</td>\n",
              "      <td>0.793835</td>\n",
              "      <td>0.000963</td>\n",
              "      <td>0.790885</td>\n",
              "      <td>-0.916222</td>\n",
              "      <td>23.815051</td>\n",
              "      <td>0.001574</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.378422</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.377606</td>\n",
              "      <td>-1.675707</td>\n",
              "      <td>11.352647</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>73.155556</td>\n",
              "      <td>61.285313</td>\n",
              "      <td>76.166667</td>\n",
              "      <td>3.425780</td>\n",
              "      <td>2194.666667</td>\n",
              "      <td>19.293753</td>\n",
              "      <td>0.701381</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.745257</td>\n",
              "      <td>2.406221</td>\n",
              "      <td>21.041421</td>\n",
              "      <td>0.008772</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>3.120945</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>3.105660</td>\n",
              "      <td>-0.103505</td>\n",
              "      <td>93.628362</td>\n",
              "      <td>0.000703</td>\n",
              "      <td>84.777778</td>\n",
              "      <td>1.527458</td>\n",
              "      <td>84.333333</td>\n",
              "      <td>-0.977876</td>\n",
              "      <td>2543.333333</td>\n",
              "      <td>3.900179</td>\n",
              "      <td>0.698708</td>\n",
              "      <td>0.014633</td>\n",
              "      <td>0.681655</td>\n",
              "      <td>4.770574</td>\n",
              "      <td>20.961227</td>\n",
              "      <td>0.031894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>2.678209</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>2.677381</td>\n",
              "      <td>-0.727722</td>\n",
              "      <td>80.346274</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>74.555556</td>\n",
              "      <td>7.220945</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.865552</td>\n",
              "      <td>2236.666667</td>\n",
              "      <td>16.161541</td>\n",
              "      <td>0.790332</td>\n",
              "      <td>0.004308</td>\n",
              "      <td>0.790885</td>\n",
              "      <td>0.386511</td>\n",
              "      <td>23.709968</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>629</th>\n",
              "      <td>1.228856</td>\n",
              "      <td>0.000342</td>\n",
              "      <td>1.228508</td>\n",
              "      <td>-1.158179</td>\n",
              "      <td>36.865673</td>\n",
              "      <td>0.000804</td>\n",
              "      <td>80.933333</td>\n",
              "      <td>3.305747</td>\n",
              "      <td>80.333333</td>\n",
              "      <td>4.022358</td>\n",
              "      <td>2428.000000</td>\n",
              "      <td>2.051780</td>\n",
              "      <td>0.730601</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>0.724517</td>\n",
              "      <td>0.257702</td>\n",
              "      <td>21.918032</td>\n",
              "      <td>0.001117</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>0.659290</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.659197</td>\n",
              "      <td>-1.183209</td>\n",
              "      <td>19.778713</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>72.077778</td>\n",
              "      <td>3.982248</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>-0.156441</td>\n",
              "      <td>2162.333333</td>\n",
              "      <td>5.004645</td>\n",
              "      <td>0.821304</td>\n",
              "      <td>0.000839</td>\n",
              "      <td>0.824069</td>\n",
              "      <td>0.283480</td>\n",
              "      <td>24.639120</td>\n",
              "      <td>0.001536</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>631</th>\n",
              "      <td>0.519258</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.512998</td>\n",
              "      <td>-1.221257</td>\n",
              "      <td>15.577747</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>76.400000</td>\n",
              "      <td>1.489655</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>-0.837560</td>\n",
              "      <td>2292.000000</td>\n",
              "      <td>2.299370</td>\n",
              "      <td>0.751249</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.752171</td>\n",
              "      <td>-0.698495</td>\n",
              "      <td>22.537467</td>\n",
              "      <td>0.000952</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>632 rows Ã— 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     gsr_mean   gsr_var   gsr_med  ...      rr_cs     rr_ps  label\n",
              "0    1.629602  0.000573  1.633575  ...  28.272768  0.000989      0\n",
              "1    0.574807  0.015033  0.655739  ...  24.124768  0.006959      1\n",
              "2    1.020229  0.001051  1.039323  ...  27.719701  0.008351      1\n",
              "3    1.507063  0.002732  1.504966  ...  23.815051  0.001574      0\n",
              "4    0.378422  0.000007  0.377606  ...  21.041421  0.008772      1\n",
              "..        ...       ...       ...  ...        ...       ...    ...\n",
              "627  3.120945  0.000644  3.105660  ...  20.961227  0.031894      0\n",
              "628  2.678209  0.000057  2.677381  ...  23.709968  0.006209      1\n",
              "629  1.228856  0.000342  1.228508  ...  21.918032  0.001117      0\n",
              "630  0.659290  0.000012  0.659197  ...  24.639120  0.001536      0\n",
              "631  0.519258  0.000314  0.512998  ...  22.537467  0.000952      0\n",
              "\n",
              "[632 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToESW1ygnOMO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "14618420-a7c9-4cf9-8634-fb2c645b6ed7"
      },
      "source": [
        "np.corrcoef(hr_ps,gsr_ps)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.03569933],\n",
              "       [-0.03569933,  1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CYGptUHrgs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = StratifiedKFold(5, shuffle = True)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbwPI3u71cLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['label']\n",
        "X = df.drop(columns = 'label')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify = y, test_size=0.3)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Th7z2NGoVGM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "39f27d45-ae64-4554-c452-9bbe35de6afd"
      },
      "source": [
        "dict_logi = { 'C': [7.5,8.0,9.0,10.0,12] ,\n",
        "             'penalty': ['l2','l1'],\n",
        "             'fit_intercept': [True, False]\n",
        "}\n",
        "clf_logi = GridSearchCV(estimator = LogisticRegression(max_iter=1000, random_state=SEED),\n",
        "                        param_grid = dict_logi,\n",
        "                        cv = cv,\n",
        "                        n_jobs=-1\n",
        "                        )\n",
        "\n",
        "clf_logi.fit(X_train,y_train)\n",
        "clf_logi.score(X_train,y_train) , clf_logi.score(X_test, y_test), clf_logi.best_estimator_"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.620253164556962,\n",
              " 0.5949367088607594,\n",
              " LogisticRegression(C=8.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                    random_state=1729, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                    warm_start=False))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hee5jZyuoloJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7763f4d1-9334-4a20-e581-5e5fff52f23d"
      },
      "source": [
        "#X_train, X_test, y_train, y_test = train_test_split()\n",
        "dict_clf = { 'max_depth': [8,15,12,20] ,\n",
        "             'learning_rate': [0.1,1,2.0],\n",
        "            'n_estimators': [5,10,100,150],\n",
        "            'reg_alpha': [0,1,10,100],\n",
        "            'reg_lambda':[10,100,150]\n",
        "}\n",
        "clf = GridSearchCV(estimator = xgb.XGBClassifier(n_jobs=-1, random_state=SEED),\n",
        "                        param_grid = dict_clf,\n",
        "                        cv = cv,\n",
        "                        n_jobs=-1\n",
        "                        )\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "clf.score(X_train,y_train) , clf.score(X_test, y_test), clf.best_estimator_"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8778280542986425,\n",
              " 0.5894736842105263,\n",
              " XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "               colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "               learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
              "               min_child_weight=1, missing=None, n_estimators=10, n_jobs=-1,\n",
              "               nthread=None, objective='binary:logistic', random_state=1729,\n",
              "               reg_alpha=0, reg_lambda=10, scale_pos_weight=1, seed=None,\n",
              "               silent=None, subsample=1, verbosity=1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDK70izb054L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3495e0b5-5d4b-44f8-e14c-0b8ddb89978d"
      },
      "source": [
        "dict_clf = { 'max_depth': [10,12,18] ,\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'n_estimators': [100,150,200,250],\n",
        "             'min_samples_split': [3,5]\n",
        "}\n",
        "clf = GridSearchCV(estimator = ExtraTreesClassifier(n_jobs=-1, random_state= SEED, oob_score =True, \n",
        "                                                    bootstrap = True),\n",
        "                        param_grid = dict_clf,\n",
        "                        cv = cv,\n",
        "                        n_jobs=-1\n",
        "                        )\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "clf.score(X_train,y_train) , clf.score(X_test, y_test), clf.best_estimator_ "
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9140271493212669,\n",
              " 0.6421052631578947,\n",
              " ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                      criterion='entropy', max_depth=10, max_features='auto',\n",
              "                      max_leaf_nodes=None, max_samples=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=5,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
              "                      oob_score=True, random_state=1729, verbose=0,\n",
              "                      warm_start=False))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3SNaDXl6b2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ae0ac0c1-62e1-4cb6-ca8f-dc4c738f72e2"
      },
      "source": [
        "dict_clf = { 'max_depth': [10,12,18] ,\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'n_estimators': [200,250],\n",
        "             'min_samples_split': [5,8]\n",
        "}\n",
        "clf = GridSearchCV(estimator = ExtraTreesClassifier(n_jobs=-1, random_state= SEED, oob_score =True, \n",
        "                                                    bootstrap = True),\n",
        "                        param_grid = dict_clf,\n",
        "                        cv = cv,\n",
        "                        n_jobs=-1\n",
        "                        )\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "clf.score(X_train,y_train) , clf.score(X_test, y_test), clf.best_estimator_ "
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9683257918552036,\n",
              " 0.6210526315789474,\n",
              " ExtraTreesClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                      criterion='gini', max_depth=12, max_features='auto',\n",
              "                      max_leaf_nodes=None, max_samples=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=5,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1,\n",
              "                      oob_score=True, random_state=1729, verbose=0,\n",
              "                      warm_start=False))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIdJeTjRyLAt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55eb5fa7-b574-4ca5-f352-28d40bc011d0"
      },
      "source": [
        "dict_clf = { 'max_depth': [10,12,18] ,\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'n_estimators': [100,150,200,250],\n",
        "             'min_samples_split': [3,5]\n",
        "}\n",
        "clf = GridSearchCV(estimator = RandomForestClassifier(n_jobs=-1, random_state= SEED, oob_score =True, \n",
        "                                                    bootstrap = True),\n",
        "                        param_grid = dict_clf,\n",
        "                        cv = cv,\n",
        "                        n_jobs=-1\n",
        "                        )\n",
        "\n",
        "clf.fit(X_train,y_train)\n",
        "clf.score(X_train,y_train) , clf.score(X_test, y_test), clf.best_estimator_ "
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 593, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 504, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 236, in set_params\n    (key, self))\nValueError: Invalid parameter learning_rate for estimator RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-4660ac0bbc1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                         )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    538\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid parameter learning_rate for estimator RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXecn1wm3gjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_classifiers = {\n",
        "    \"Logistic Regression\": LogisticRegression( C =8.0 ,max_iter=1000 , random_state=SEED),\n",
        "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"SVM\": SVC(kernel='rbf'),\n",
        "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=1000),\n",
        "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=1000),\n",
        "    \"Neural Net\": MLPClassifier(alpha = 1),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    \"QDA\": QuadraticDiscriminantAnalysis(),\n",
        "    \"Gaussian Process\": GaussianProcessClassifier(),\n",
        "    \"XGBoost\": xgb.XGBClassifier(n_jobs=-1, random_state=SEED)\n",
        "}"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGvOmfgBnOMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 5, verbose = True):\n",
        "    \n",
        "    dict_models = {}\n",
        "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
        "        t_start = time.clock()\n",
        "        classifier.fit(X_train, Y_train)\n",
        "        t_end = time.clock()\n",
        "        \n",
        "        t_diff = t_end - t_start\n",
        "        train_score = classifier.score(X_train, Y_train)\n",
        "        test_score = classifier.score(X_test, Y_test)\n",
        "        \n",
        "        dict_models[classifier_name] = {'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff}\n",
        "        if verbose:\n",
        "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
        "    return dict_models\n",
        "\n",
        "\n",
        "\n",
        "def display_dict_models(dict_models, sort_by='test_score'):\n",
        "    cls = [key for key in dict_models.keys()]\n",
        "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
        "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
        "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
        "    \n",
        "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls),4)), columns = ['classifier', 'train_score', 'test_score', 'train_time'])\n",
        "    for ii in range(0,len(cls)):\n",
        "        df_.loc[ii, 'classifier'] = cls[ii]\n",
        "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
        "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
        "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
        "    \n",
        "    display(df_.sort_values(by=sort_by, ascending=False))"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIGJKmhenOMb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "5f899a09-954e-491e-d151-5edb24afdd79"
      },
      "source": [
        "dict_models = batch_classify(X_train, y_train, X_test, y_test, no_classifiers = 12)\n",
        "display_dict_models(dict_models)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trained Logistic Regression in 0.20 s\n",
            "trained Nearest Neighbors in 0.00 s\n",
            "trained SVM in 0.02 s\n",
            "trained Gradient Boosting Classifier in 2.84 s\n",
            "trained Decision Tree in 0.01 s\n",
            "trained Random Forest in 2.13 s\n",
            "trained Neural Net in 0.07 s\n",
            "trained Naive Bayes in 0.00 s\n",
            "trained AdaBoost in 0.26 s\n",
            "trained QDA in 0.00 s\n",
            "trained Gaussian Process in 0.15 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "trained XGBoost in 0.22 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classifier</th>\n",
              "      <th>train_score</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.620253</td>\n",
              "      <td>0.594937</td>\n",
              "      <td>0.202202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.945148</td>\n",
              "      <td>0.594937</td>\n",
              "      <td>0.220767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.588608</td>\n",
              "      <td>0.007496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.569620</td>\n",
              "      <td>2.844042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.569620</td>\n",
              "      <td>2.125011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.808017</td>\n",
              "      <td>0.569620</td>\n",
              "      <td>0.259321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>QDA</td>\n",
              "      <td>0.518987</td>\n",
              "      <td>0.563291</td>\n",
              "      <td>0.002771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Gaussian Process</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.537975</td>\n",
              "      <td>0.154772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nearest Neighbors</td>\n",
              "      <td>0.710970</td>\n",
              "      <td>0.531646</td>\n",
              "      <td>0.002044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Neural Net</td>\n",
              "      <td>0.516878</td>\n",
              "      <td>0.531646</td>\n",
              "      <td>0.070775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.556962</td>\n",
              "      <td>0.531646</td>\n",
              "      <td>0.003594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.506329</td>\n",
              "      <td>0.525316</td>\n",
              "      <td>0.015296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      classifier  train_score  test_score  train_time\n",
              "0            Logistic Regression     0.620253    0.594937    0.202202\n",
              "11                       XGBoost     0.945148    0.594937    0.220767\n",
              "4                  Decision Tree     1.000000    0.588608    0.007496\n",
              "3   Gradient Boosting Classifier     1.000000    0.569620    2.844042\n",
              "5                  Random Forest     1.000000    0.569620    2.125011\n",
              "8                       AdaBoost     0.808017    0.569620    0.259321\n",
              "9                            QDA     0.518987    0.563291    0.002771\n",
              "10              Gaussian Process     1.000000    0.537975    0.154772\n",
              "1              Nearest Neighbors     0.710970    0.531646    0.002044\n",
              "6                     Neural Net     0.516878    0.531646    0.070775\n",
              "7                    Naive Bayes     0.556962    0.531646    0.003594\n",
              "2                            SVM     0.506329    0.525316    0.015296"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J12_IpZnnOMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "8b282f57-6ad0-4548-b702-fec1bbffcc95"
      },
      "source": [
        "GDB_params = {\n",
        "    'n_estimators': [100, 500, 1000],\n",
        "    'learning_rate': [0.5, 0.1, 0.01, 0.001],\n",
        "    'criterion': ['friedman_mse', 'mse', 'mae']\n",
        "}\n",
        "\n",
        "df_train, df_test, X_train, Y_train, X_test, Y_test = get_train_test(df, y_col, x_cols, 0.6)\n",
        "\n",
        "for n_est in GDB_params['n_estimators']:\n",
        "    for lr in GDB_params['learning_rate']:\n",
        "        for crit in GDB_params['criterion']:\n",
        "            clf = GradientBoostingClassifier(n_estimators=n_est, \n",
        "                                             learning_rate = lr,\n",
        "                                             criterion = crit)\n",
        "            clf.fit(X_train, Y_train)\n",
        "            train_score = clf.score(X_train, Y_train)\n",
        "            test_score = clf.score(X_test, Y_test)\n",
        "            print(\"For ({}, {}, {}) - train, test score: \\t {:.5f} \\t-\\t {:.5f}\".format(n_est, lr, crit[:4], train_score, test_score))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For (100, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.56917\n",
            "For (100, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.56522\n",
            "For (100, 0.5, mae) - train, test score: \t 0.74670 \t-\t 0.56917\n",
            "For (100, 0.1, frie) - train, test score: \t 0.98945 \t-\t 0.54941\n",
            "For (100, 0.1, mse) - train, test score: \t 0.98945 \t-\t 0.54150\n",
            "For (100, 0.1, mae) - train, test score: \t 0.73879 \t-\t 0.56522\n",
            "For (100, 0.01, frie) - train, test score: \t 0.81003 \t-\t 0.56126\n",
            "For (100, 0.01, mse) - train, test score: \t 0.81003 \t-\t 0.56126\n",
            "For (100, 0.01, mae) - train, test score: \t 0.74142 \t-\t 0.56917\n",
            "For (100, 0.001, frie) - train, test score: \t 0.67810 \t-\t 0.52964\n",
            "For (100, 0.001, mse) - train, test score: \t 0.67810 \t-\t 0.52964\n",
            "For (100, 0.001, mae) - train, test score: \t 0.72559 \t-\t 0.56522\n",
            "For (500, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.53755\n",
            "For (500, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.54941\n",
            "For (500, 0.5, mae) - train, test score: \t 0.74670 \t-\t 0.56917\n",
            "For (500, 0.1, frie) - train, test score: \t 1.00000 \t-\t 0.54941\n",
            "For (500, 0.1, mse) - train, test score: \t 1.00000 \t-\t 0.55336\n",
            "For (500, 0.1, mae) - train, test score: \t 0.74142 \t-\t 0.54545\n",
            "For (500, 0.01, frie) - train, test score: \t 0.91293 \t-\t 0.55731\n",
            "For (500, 0.01, mse) - train, test score: \t 0.91293 \t-\t 0.55731\n",
            "For (500, 0.01, mae) - train, test score: \t 0.73351 \t-\t 0.56522\n",
            "For (500, 0.001, frie) - train, test score: \t 0.78364 \t-\t 0.55731\n",
            "For (500, 0.001, mse) - train, test score: \t 0.78364 \t-\t 0.55731\n",
            "For (500, 0.001, mae) - train, test score: \t 0.73351 \t-\t 0.56126\n",
            "For (1000, 0.5, frie) - train, test score: \t 1.00000 \t-\t 0.54545\n",
            "For (1000, 0.5, mse) - train, test score: \t 1.00000 \t-\t 0.53755\n",
            "For (1000, 0.5, mae) - train, test score: \t 0.75462 \t-\t 0.55336\n",
            "For (1000, 0.1, frie) - train, test score: \t 1.00000 \t-\t 0.55336\n",
            "For (1000, 0.1, mse) - train, test score: \t 1.00000 \t-\t 0.55336\n",
            "For (1000, 0.1, mae) - train, test score: \t 0.74670 \t-\t 0.54941\n",
            "For (1000, 0.01, frie) - train, test score: \t 0.98681 \t-\t 0.56126\n",
            "For (1000, 0.01, mse) - train, test score: \t 0.98681 \t-\t 0.56126\n",
            "For (1000, 0.01, mae) - train, test score: \t 0.73351 \t-\t 0.56126\n",
            "For (1000, 0.001, frie) - train, test score: \t 0.80739 \t-\t 0.55731\n",
            "For (1000, 0.001, mse) - train, test score: \t 0.80739 \t-\t 0.55731\n",
            "For (1000, 0.001, mae) - train, test score: \t 0.73351 \t-\t 0.56126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWMUdQ9cnOMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}